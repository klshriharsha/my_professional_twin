{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7546c627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:35:47.001448Z",
     "start_time": "2026-01-19T12:35:37.450778Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import gradio as gr\n",
    "from openai.types.responses import Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b367072",
   "metadata": {},
   "source": [
    "### Load environment variables and intialize OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2beec8d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:35:49.901184Z",
     "start_time": "2026-01-19T12:35:49.877234Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9baa09c",
   "metadata": {},
   "source": [
    "### Prepare input files for the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33b89353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:35:54.862710Z",
     "start_time": "2026-01-19T12:35:50.930763Z"
    }
   },
   "outputs": [],
   "source": [
    "resume_pdf_file = client.files.create(\n",
    "    file=open(\"data/resume.pdf\", \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")\n",
    "linkedin_pdf_file = client.files.create(\n",
    "    file=open(\"data/linkedin.pdf\", \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c652bf3",
   "metadata": {},
   "source": [
    "### Prepare tools for the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88f8f1c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:35:54.886746Z",
     "start_time": "2026-01-19T12:35:54.878057Z"
    }
   },
   "outputs": [],
   "source": [
    "def notify(title: str, message: str):\n",
    "    return requests.post(\n",
    "        \"https://api.pushover.net/1/messages.json\",\n",
    "        data={\n",
    "            \"token\": os.getenv(\"PUSHOVER_KEY\"),\n",
    "            \"user\": os.getenv(\"PUSHOVER_EMAIL\"),\n",
    "            \"title\": title,\n",
    "            \"message\": message,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def record_unknown_question(question: str) -> str:\n",
    "    notify(title=\"Unknown question recorded\", message=question)\n",
    "    return \"recorded_successfully\"\n",
    "\n",
    "\n",
    "def record_user_details(email: str, name=\"Unknown\", notes=\"NA\") -> str:\n",
    "    notify(title=\"User details recorded\", message=f\"Email: {email}\\nName: {name}\\nNotes: {notes}\")\n",
    "    return \"recorded_successfully\"\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"record_unknown_question\",\n",
    "        \"description\": \"Record an unknown question asked by the user.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The question that the user asked\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"question\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"record_user_details\",\n",
    "        \"description\": \"Record the user's details to reach out to them later.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the user\",\n",
    "                },\n",
    "                \"email\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The email of the user\",\n",
    "                },\n",
    "                \"notes\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Any additional notes for context\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"email\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af737503",
   "metadata": {},
   "source": [
    "### Prepare helpers to call OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187c554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:35:54.905102Z",
     "start_time": "2026-01-19T12:35:54.887381Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai.types.responses import ResponseCustomToolCall\n",
    "from openai.types.responses.response import Response\n",
    "\n",
    "def call_openai(input_list: list[dict]):\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        tools=tools,\n",
    "        prompt={\n",
    "            \"id\": os.getenv(\"PROMPT_ID\"),\n",
    "            \"variables\": {\n",
    "                \"resume_pdf\": {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": resume_pdf_file.id\n",
    "                },\n",
    "                \"linkedin_pdf\": {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": linkedin_pdf_file.id\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        input=input_list\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def handle_openai_response(response: Response, history) -> str:\n",
    "    output = response.output[0]\n",
    "\n",
    "    if output.type == \"function_call\":\n",
    "        return call_tool(output, history)\n",
    "\n",
    "    elif output.type == \"message\":\n",
    "        return response.output_text\n",
    "\n",
    "    else:\n",
    "        return \"unknown_response_type\"\n",
    "\n",
    "def call_tool(output: ResponseCustomToolCall, history) -> str:\n",
    "    arguments = json.loads(output.arguments)\n",
    "\n",
    "    if output.name == \"record_unknown_question\":\n",
    "        return record_unknown_question(arguments[\"question\"])\n",
    "    if output.name == \"record_user_details\":\n",
    "        return record_user_details(arguments[\"email\"], arguments[\"name\"], arguments[\"notes\"])\n",
    "    \n",
    "    return \"unknown_tool\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab15382",
   "metadata": {},
   "source": [
    "### Launch the chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "227dd97f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:35:56.508798Z",
     "start_time": "2026-01-19T12:35:55.833469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2147, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1627, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 1001, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/gradio/chat_interface.py\", line 541, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/gradio/chat_interface.py\", line 902, in _submit_fn\n",
      "    response = await run_sync(self.fn, *inputs, limiter=self.limiter)  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 61, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/6c/8lw84sp94ysf28jy15d_10fc0000gn/T/ipykernel_14291/2202252828.py\", line 19, in chat\n",
      "    response = call_openai(messages)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/6c/8lw84sp94ysf28jy15d_10fc0000gn/T/ipykernel_14291/2726903924.py\", line 6, in call_openai\n",
      "    response = client.responses.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py\", line 866, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Shriharsha.Kowshika/Projects/my_professional_twin/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': 'No tool output found for function call call_AYbJMzunljmhQ1TMmbdQHEoS.', 'type': 'invalid_request_error', 'param': 'input', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "def get_history(history):\n",
    "    history_list = []\n",
    "    for message in history:\n",
    "        for c in message[\"content\"]:\n",
    "            history_list.append({\"role\": message[\"role\"], \"content\": c[\"text\"]})\n",
    "    return history_list\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = get_history(history) + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = call_openai(messages)\n",
    "    output_text = handle_openai_response(response, history)\n",
    "    \n",
    "    if output_text == \"recorded_successfully\":\n",
    "        messages = messages + response.output + [{\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": response.output[0].call_id,\n",
    "            \"output\": output_text\n",
    "        }]\n",
    "        response = call_openai(messages)\n",
    "        output_text = handle_openai_response(response, history)\n",
    "\n",
    "    return output_text\n",
    "\n",
    "\n",
    "gr.ChatInterface(fn=chat, title=\"Chat with Shriharsha's professional twin\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7ab16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
